# -*- coding: utf-8 -*-
"""Fashion_mnist.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yvL4hb1HHQPqiAszryQCmhx7IDID1xXf

# Instalado o TensorFlow
"""
#pip uninstall -y tensorflow #Comando necessário, pois o TensorFlow-gpu não desinstala a versão mais recente do Tensorflow, pode gerar conflitos.
#

"""# Instalando as blibliotecas"""

import numpy as np
import datetime
import tensorflow as tf
from tensorflow.keras.datasets import fashion_mnist

tf.__version__

"""# Pré Processamento da base de dados"""

(x_train,y_train),(x_test,y_test) = fashion_mnist.load_data()

x_train[0]

y_train

"""## Normalizando a Base de dados
A base de dados tem ser normalizada pois possui muitos valores, fazendo com que demore mais para ser executada
"""

x_train/255.0
x_test/255.0

"""## Remodelando a base dados"""

x_train.shape

#Como o formato das imagens é 28x28 Pixels, precisamos deixalas em formato de vetor,então fica 28*28 para criar um vetor com essa quantidade de 784 posições
x_train=x_train.reshape(-1,28*28)#(-1 ) significa que quer fazer isso com todas as imagens

x_train.shape

#Realizando o mesmo procedimento na base de teste
x_test= x_test.reshape(-1,28*28)

x_test.shape

"""# Construção da Rede Neural

## Definição do modelo de Rede Neural
"""

model = tf.keras.models.Sequential()

model

"""## Primeira camada densa(Fully-Conected)"""

model.add(tf.keras.layers.Dense(units=128, activation='relu', input_shape=(784, )))#units é o numero de neuronios, relu a função de ativação, e input_shape o numero de entradas

"""## Adicionando o  dropout
Droput é uma técnica que trabsforma alguns neuronios para 0, afim de evitar overffiting
"""

model.add(tf.keras.layers.Dropout(0.2))#zera 20% dos neuronios dessa camada

"""## Camada de Saida"""

model.add(tf.keras.layers.Dense(units=10, activation='softmax'))#units é o numero de classses, sofmax o tipo de ativação, pois tem mais de uma classe

"""## Compilação do Modelo"""

model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['sparse_categorical_accuracy'])#loss é a função do erro, optmizer é o grandiente para achar o minimo global
#metrics é avaliação do percentual de acertos

model.summary()

"""## Treinamento do Modelo"""

model.fit(x_train,y_train,epochs=5)

"""## Avaliação do modelo"""

test_loss,test_accuracy= model.evaluate(x_test,y_test)

print("Test acurracy{}".format(test_accuracy))

test_loss